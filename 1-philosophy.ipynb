{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence as a Philosophical Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Philip Agre, in \"The Soul Gained and Lost\", argues that \"AI is philosophy underneath\"[Agre 1995]. To validate this claim he traces the idea of Cartesian dualism in AI research, from the 1950s into the 1990s, suggesting that specific technical roadblocks in the AI research of that time can be directly related to the incongruity of Descartes' mechanism and Descartes' insistence on an eternal soul. While the lucidity of Agre's full argument is hard to argue with, we might consider the question: does it still hold? Is the current generation of machine learning algorithms susceptible to the same pitfalls as the rule-based artificial intelligence of the 1990s, the time Agre was writing? In other words, is it still meaningful to trace the effects of Cartesian dualism – or any other philosophical system – in present day machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I claim that the answer is yes, and, even more so, that Cartesian dualism continues to produce technical roadblocks in AI research today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.npl.co.uk/upload/img/turing-race.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">Alan Turing finishing second in a three mile race, 1949 ([source](http://www.npl.co.uk/upload/img/turing-race.jpg))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show this, we have to go back to the most influential text on artificial intelligence ever written, Turing's 1950 essay \"Computing Machinery and Intelligence\"[Turing 1950] – Scott Aaronsen famously maintains that \"one can divide everything that’s been said about artificial intelligence into two categories: the 70% that’s somewhere in Turing’s paper from 1950, and the 30% that’s emerged from a half-century of research since then.\" [Aaronsen 2013]. In the essay, Turing devises an experimental setup, later known as the Turing test, to operationalize the question \"Can machines think?\". Turing, however, also reacts directly to the problem of Cartesian dualism. In his refutation of the \"Argument from consciousness\", he quotes Geoffrey Jefferson who argues that it is not sufficient for a machine to write a sonnet to be considered intelligent, but that it would also need to be able to relate internally to its writing, that it would need to \"know that it has written it\" [Turing 1950, 446]. As Turing summarizes: \"According to the most extreme form of this view the only way by which one could be sure that a machine thinks is to be the machine and to feel oneself thinking.\" [ibd.] Turing artfully avoids any further discussion of this argument by concluding that taking this extreme solipsism seriously would cast doubt not only on the machine's capability to think but also on the human capability to think. He concludes: \"Instead of arguing continually over this point it is usual to have the polite convention that everyone thinks.\" [ibd.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussing this internal requirement for intelligence, both Jefferson and Turing mention learning something \"in parrot fashion\" [Turing, 1950, 446, Jefferson 1949, 1100], i.e. learning something without understanding it. Jefferson makes explicit [Jefferson:1949, 1106] that this expression is of course a reference to Descartes' original argument that \"magpies and parrots can utter words as we do, and yet cannot speak like us\" [Descartes 2006, 47]. Descartes' famous argument, in the fifth chapter of the \"Discours de la méthode\" [Descartes 2006, 46f], goes like this: \n",
    "\n",
    "> If there were [such] machines having the organs and outward shape of a monkey or any other irrational animal, we would have no means of knowing that they were not of exactly the same nature as these animals, whereas, if any such machines resembled us in body and imitated our actions insofar as this was practically possible, we should still have two very certain means of recognizing that they were not, for all that, real human beings. The first is that they would never be able to use words or other signs by composing them as we do to declare our thoughts to others. For we can well conceive of a machine made in such a way that it emits words [...] but it is not conceivable that it should put these words in different orders to correspond to the meaning of things said in its presence [...]. And the second means is that, although such machines might do many things as well or even better than any of us, they would inevitably fail to do some others, by which we would discover that they did not act consciously, but only because their organs were disposed in a certain way. For, whereas reason is a universal instrument which can operate in all sorts of situations, their organs have to have a particular disposition for each particular action, from which it follows that it is practically impossible for there to be enough different organs in a machine to cause it to act in all of life’s occurrences in the same way that our reason causes us to act.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To paraphrase, the infinite flexibility of language used by humans stands out in contrast to the completely mechanical disposition of the animal, even given all possible \"permutations\" of its organs, i.e. all possible mechanical states. More importantly, it stands out against the completely mechanical disposition of a mechanical human, who will – in the framework of Descartes' thought experiment – be as limited in its relation to the world as the animal. According to Descartes, the mind is exceptional exactly because it has this faculty: to process every possible situation by means of language, and react to it. We will call this assumption the exceptionality of the mind. The consequence of this exceptionality of the mind, for Descartes, is the existence of an immortal soul, in correspondence to the existence of God, which he proves (a slightly more complex version of Anselm of Canterbury's original ontological argument) in the previous chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, already in Descartes, the assumption of the exceptionality of the mind is made on the basis of a machine, albeit a machine within a thought experiment. Nevertheless, from there it is only a small step to Searle's Chinese room argument [Searle, 1980]. Here is Searle himself [Searle 1999, 115]: \n",
    "\n",
    "> Imagine a native English speaker who knows no Chinese locked in a room full of boxes of Chinese symbols (a data base) together with a book of instructions for manipulating the symbols (the program). Imagine that people outside the room send in other Chinese symbols which, unknown to the person in the room, are questions in Chinese (the input). And imagine that by following the instructions in the program the man in the room is able to pass out Chinese symbols which are correct answers to the questions (the output). The program enables the person in the room to pass the Turing Test for understanding Chinese but he does not understand a word of Chinese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its simplest form, the argument is an \"update\" of Leibniz' mill, a thought experiment which appears in section 17 of the Monadology. Suppose humans are mechanisms, the argument goes, then we could increase the size of such a human mechanism until we can walk around in it like a mill. Everything that constitutes the mechanism would still be there, only larger. We could then enter the mechanism, walk around in it, and examine all the parts and their interconnections. Doing that, we would find no part or sub-mechanism corresponding to the soul, hence the soul must be  – exactly in the spirit of Descartes – a \"simple\" and separate substance. In more computational terms, we could also call this the black box problem of the soul: every attempt to pinpoint the location of the soul (or of \"intelligence\", for that matter) within a mechanism will leave us with an irreducible black box, as demonstrated by Agre for the AI research of the 1950s to the 1990s. The paradox is most explicit in Descartes, who explicitly states that it is not sufficient for the soul to be \"lodged in the human body like a pilot in his ship [...] but that it needs to be more closely joined and united with the body in order to have, in addition, feelings and appetites like the ones we have, and in this way compose a true man.\" [Descartes 2006, 48]. In other words, for Descartes, the exceptionality of the mind also implies an ontological exceptionality: it is nowhere and everywhere at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to Searle. As he explicitly states in the beginning, his argument is a refutation of computationalism, an argument against the supposition that mental states are sufficiently described as computational states. The wider philosophical implications of this argument include a statement about the relation of syntax and semantics, to wit that syntax is not a sufficient condition for semantics. Computers, however, consist of symbols all the way down. Hence, the Turing test – which operates exclusively on syntactic premises  – is not a sufficient measure of intelligence. What Searle proposes instead as a sufficient measure of intelligence is intentionality, a philosophical concept first proposed by Franz Brentano and later famously taken up by his student Edmund Husserl. It is impossible to reproduce the complete philosophical discourse around intentionality here, so we will focus on one specific aspect: its relation to dualism. Intentionality is the faculty of human minds to \"be about, to represent, or to stand for things, properties, and states of affairs\" (Jacob 2014). In other words, intentionality describes the directedness of a thought towards something other than itself, be it material or immaterial, internal or external. A direct consequence of this non-identity of a thought with itself is, at minimum the exceptionality of the mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time – this is one of Searle's main conclusions – the proponents of computationalism establish their own kind of dualism, despite their insistence on a purely mechanistic perspective. If mental states are computational states, i.e. \"mental operations consist in computational operations on formal symbols\" [Searle 1980, 424] then the (biological) brain is just one of many possible (most likely Turing-complete) hardware options. Hence, the exceptionality of the mind is again something immaterial, even if it is just an epiphenomenon of computation.\n",
    "\n",
    "With Searle, the incongruity of dualism and mechanism, described by Agre as one of the major philosophical roadblocks of AI research, thus becomes even more apparent. Searle's conclusion that at the end of the day, mechanism implies dualism as much as dualism implies dualism, is Descartes argument for the eternal soul put on its secular feet. We should remember, however, that Searle's text, much like Agre's, is a reaction to computer science experiments trying to establish a rule-based artificial intelligence. Today, while Siri and her cousins are certainly much more effective at communication than any rule-based AI system in the 1980s or 1990s, no serious AI researcher would make the claim that they are intelligent, or that they show intentionality. Hence, the claim that Cartesian dualism continues to be an issue for AI research, and even a weaker version of this claim, that Cartesian dualism continues to be an important reference point for AI research, seem not to hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why this impression is wrong, we have to turn to Thomas Nagel's consideration of the question \"What is it like to be a bat\". While his text is primarily an argument against reductionism (i.e. against the philosophical version of divide and conquer) and does not talk about artificial intelligence at all, we can nevertheless understand it as the missing link between good old fashioned AI research, Cartesian dualism, and contemporary machine learning. His position is summarized neatly on the second page of the text: \"[...] fundamentally an organism has conscious mental states if and only if there is something that it is like to be that organism – something it is like for the organism.\" [Nagel 1974, 436] Nagel calls this the \"subjective character of experience\". Why is it a refutation of reductionism? Because even if an external observer would be able to attain all the facts about someone else's inherently alien experience (analyze it in terms of \"functional states\"), he would still not be able to reconstruct said experience from these facts. Reductionism is false because it disregards this surplus generated by the subjective character of experience. Historically, this is knows as the knowledge argument against physicalism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/9s1KH.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">What is it like to bea bat? ([source](https://i.stack.imgur.com/9s1KH.jpg))</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, if this argument seems familiar, it is not only because of its similarity with Searle's argument (albeit Nagel would most likely disapprove of intentionality as a replacement for the subjective character of experience), but also because it is, again, Descartes secularized. For Descartes and Nagel (and Searle, for that matter), there exists an unattainable surplus in the conscious existence of human beings. And while the implications of this surplus are much more radical for Descartes than for Nagel, the core argument remains the black box argument. Nagel is even closer to Descartes in that the exceptionality of subjective experience challenges its ontological status. As Nagel writes: \"I believe it is precisely this apparent clarity of the word 'is' that is deceptive.\" [Nagel 1974, 447]. Even Turing, who rejects the radical solipsism that could be constructed from this argument, admits \"I do not wish to give the impression that I think there is no mystery about conciousness. There is, for instance, something of a paradox connected with any attempt to localize it.\" [Turing 1950, 447] The important difference however is that Nagel makes the case for the exceptionality of the mind not from consciousness but from perception. In other words, if perception, not consciousness, is sufficient for dualism, dualism will be a problem for contemporary machine learning, which shifts the focus exactly from the mechanization of reason to the mechanization of perception. In the upcoming weeks, we will look at multiple examples for this problematic reappearance of dualism but I still will briefly mention here that the whole concept of activation maximization builds upon not only a generic dualism but an explicitly Cartesian dualism that presupposes an inherent order of thought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more important point here which we can make now that we arrived at Nagel: the idea of an \"alien\" perception (in Nagel's case) or consciousness (in the original Cartesian case) is strongly linked to the concept of disability. This begins with Descartes, where two kinds of disability serve as poof for the exceptionality of the mind: one are the men \"born deaf and dumb\" [Descartes 2006, 47] who still can communicate like humans, albeit not by using speech but signs, and the other is the \"child with a disturbed brain\" [Descartes:2006, 47] who still surpasses any animal in its capability to communicate. In Nagel, the first motif exactly reappears, as the \"subjective character of the experience of a person deaf and blind from birth\" [Nagel:1974, 442], and the example that \"blind people are able to detect objects near them by a form of sonar, using vocal clicks or taps of a cane\" [Nagel:1974, 441]. Finally, the classic thought experiment used to construct the knowledge argument against physicalism utilizes a scientists with a disability to make the point, see for instance Robinson's rendering of it in Stanford Encyclopedia of Philosophy [Robinson 2017, 21]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious why disability comes up here. As Thomas Nagel has put it, the \"distance between oneself and other persons and other species can fall anywhere on a continuum\" [Nagel 1974, 442] – the closest intra-species point on this continuum would exactly be a person with a perceptual disability who compensates for this disability by other means. While intuitively all this feels problematic, to say the least, it is important to note that even for Descartes, who writes at the beginning of the 17th century, the perceptual limitations of a person do not affect their humanity, as there is no middle ground between having a soul and not having a soul. While this middle ground exists for Nagel on the other hand, here its extremes simply define the objective distance between subjective experiences, and nothing else. Nevertheless, there seems to be a case to be made here about the role of disability in the philosophical roots of artificial intelligence. While much has been written about the necessity of an \"other\" for any proper definition, I think this specific case needs more investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally: the possibility of extending Agre's method and argument into contemporary machine learning suggests that the historical narrative of artificial intelligence research – a narrative against continuity – might deserve our increased attention. Indeed, the fact that the issue of dualism persist across artificial intelligence \"winters\" hints at continuity more than anything, and the upcoming weeks will show if other philosophical concepts should be added to that list as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "- Aaronsen, Scott. *Quantum Computing Since Democritus*. Cambridge University Press, 2013.\n",
    "- Agre, Philip E. \"The Soul Gained and Lost. Artificial Intelligence as a Philosophical Project.\" Stanford Humanities Review 4, no. 2 (1995): 1–19.\n",
    "- Cole, David. \"The Chinese Room Argument.\" In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Winter 2015. https://plato.stanford.edu/entries/chinese-room/.\n",
    "- Descartes, René. *A Discourse on the Method*. Oxford University Press, 2006.\n",
    "- Jacob, Pierre. \"Intentionality.\" In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Winter 2014. https://plato.stanford.edu/ entries/intentionality/.\n",
    "- Jefferson, Geoffrey. \"The Mind of Mechanical Man.\" British Medical Journal 1, no. 4616 (1949): 1105–10.\n",
    "- Nagel, Thomas. \"What Is It Like to Be a Bat?\" The Philosophical Review 83, no. 4 (1974): 435–50.\n",
    "- Robinson, Howard. \"Dualism.\" In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Fall 2017. https://plato.stanford.edu/entries/ dualism/.\n",
    "- Searle, John R. \"Minds, Brains, and Programs.\" Behavioral and Brain Sciences 3, no. 3 (1980): 417–24.\n",
    "- Searle, John R. \"The Chinese Room.\" In The MIT Encyclopedia of the Cognitive Sciences, edited by R. A. Wilson and F. Keil. Cambridge, MA: MIT Press, 1999.\n",
    "- Turing, Alan Mathison. \"Computing Machinery and Intelligence.\" Mind 59, no. 236 (1950): 433–60."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
